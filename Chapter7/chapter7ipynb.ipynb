{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter7ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIGmCKsohiaG",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 7:\n",
        "# Working with Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs2z0E7xhisy",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mui3VBqsiOCp",
        "colab_type": "text"
      },
      "source": [
        "## Types of Data Represented as Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucrlkNZkiR86",
        "colab_type": "text"
      },
      "source": [
        "There are four kinds of string data we might see:\n",
        "- Categorical data\n",
        "- Free strings than can be semantically mapped to categories\n",
        "- Structured string data\n",
        "- Text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8iEQStRikBo",
        "colab_type": "text"
      },
      "source": [
        "In the context of text analysis, the dataset is often called the corpus, and each data point, represented as a single text, is callled a document. These\n",
        "terms come from the information retrieval (IR) and natural language processing (NLP)\n",
        "community, which both deal mostly in text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogWAri7Wj2A0",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EW2Jrtsj3sW",
        "colab_type": "text"
      },
      "source": [
        "## Example Application: Sentiment Analysis of Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYkdRs0lzTwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYkjGWbbj9O5",
        "colab_type": "code",
        "outputId": "e348bb1f-88a1-46fb-959c-407388a3a15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d iarunava/imdb-movie-reviews-dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading imdb-movie-reviews-dataset.zip to /content\n",
            " 98% 220M/224M [00:02<00:00, 135MB/s]\n",
            "100% 224M/224M [00:02<00:00, 109MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00KmVrTunWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"/content/imdb-movie-reviews-dataset.zip\") as file:\n",
        "    file.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-p7nwQpvFtb",
        "colab_type": "code",
        "outputId": "d81c7dfc-23fc-4472-980c-17cd6fb6d2a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree(\"/content/aclImdb/train/unsup\")\n",
        "\n",
        "reviews_train = load_files(\"/content/aclImdb/train\")\n",
        "# load_files return a bunch, containg training texts and training labels\n",
        "text_train, y_train = reviews_train.data, reviews_train.target\n",
        "print(\"Type of text_train: {}\".format(type(text_train)))\n",
        "print(\"Length of text_train: {}\".format(len(text_train)))\n",
        "print(\"text_train[6]:\\n{}\".format(text_train[6]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of text_train: <class 'list'>\n",
            "Length of text_train: 25000\n",
            "text_train[6]:\n",
            "b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YogBtEVnwKI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNNjSGyyIN5",
        "colab_type": "code",
        "outputId": "b099ef74-46e0-4262-a776-3cb463127fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "print(\"text_train[6]:\\n{}\".format(text_train[6]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text_train[6]:\n",
            "b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.  Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life.   I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqLBzvzuzNL7",
        "colab_type": "code",
        "outputId": "17018596-f648-4b0f-c286-8968ee5af374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Samples per class (training): {}\".format(np.bincount(y_train)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples per class (training): [12500 12500]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUgiT0ZZ01xG",
        "colab_type": "code",
        "outputId": "59bc8709-9106-43eb-f0df-f27f13d352a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reviews_test = load_files(\"/content/aclImdb/test\")\n",
        "text_test, y_test = reviews_test.data, reviews_test.target\n",
        "print(\"Number of documents in test data: {}\".format(len(text_test)))\n",
        "print(\"Samples per class (test): {}\".format(np.bincount(y_test)))\n",
        "text_test = [doc.replace(b\"<br \\>\", b\" \") for doc in text_test]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents in test data: 25000\n",
            "Samples per class (test): [12500 12500]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FirjmKwG1Yha",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7wXLtx1ZPk",
        "colab_type": "text"
      },
      "source": [
        "## Representing Text Data as a Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0xljtTZ1dRJ",
        "colab_type": "text"
      },
      "source": [
        "Computing the bag-of-words representation for a corpus of documents consists of\n",
        "the following three steps:\n",
        "1. Tokenization. Split each document into the words that appear in it (called tokens),\n",
        "for example by splitting them on whitespace and punctuation.\n",
        "2. Vocabulary building. Collect a vocabulary of all words that appear in any of the\n",
        "documents, and number them (say, in alphabetical order).\n",
        "3. Encoding. For each document, count how often each of the words in the vocabulary\n",
        "appear in this document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ysaf3NT7-da",
        "colab_type": "text"
      },
      "source": [
        "### Applying Bag-of-Words to a Toy Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQN9zmCX8hg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bards_words =[\"The fool doth think he is wise,\",\n",
        "              \"but the wise man knows himself to be a fool\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiaR-_uT8nH3",
        "colab_type": "code",
        "outputId": "7d826836-08bb-47f5-d84d-a1beec1fd916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()\n",
        "vect.fit(bards_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6y2UWTw8xky",
        "colab_type": "code",
        "outputId": "baefd28c-6211-430b-bce5-150c6c9a707c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
        "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 13\n",
            "Vocabulary content:\n",
            " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b2qOXRx8_Yf",
        "colab_type": "code",
        "outputId": "1a435bf6-d5b0-4305-dd6f-056a663ddb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bag_of_words = vect.transform(bards_words)\n",
        "print(\"bag_of_words: {}\".format(repr(bag_of_words)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag_of_words: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 16 stored elements in Compressed Sparse Row format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_PII2-S9YeQ",
        "colab_type": "code",
        "outputId": "4b436fbb-d6d3-4a58-b925-8832730714f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Dense representation of bag_of_words:\\n{}\".format(bag_of_words.toarray()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dense representation of bag_of_words:\n",
            "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
            " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxKW9q91903L",
        "colab_type": "text"
      },
      "source": [
        "### Bag-of-words for Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCwX8Z-l-Bye",
        "colab_type": "code",
        "outputId": "98563e29-d9c4-4895-baef-8d0718da4df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "vect = CountVectorizer().fit(text_train)\n",
        "X_train = vect.transform(text_train)\n",
        "print(\"X_train:\\n{}\".format(repr(X_train)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:\n",
            "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VIqqp3c-TqT",
        "colab_type": "code",
        "outputId": "f3f89dda-bcd4-48ed-98f7-4ef3bc16ee3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "feature_names = vect.get_feature_names()\n",
        "print(\"Number of features: {}\".format(len(feature_names)))\n",
        "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
        "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
        "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 74849\n",
            "First 20 features:\n",
            "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
            "Features 20010 to 20030:\n",
            "['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
            "Every 2000th feature:\n",
            "['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fea2tCG4_P1n",
        "colab_type": "code",
        "outputId": "3bf06769-f9fd-484c-ca07-039d47001ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
        "print(\"Mean cross-validation accuracy: {:.3f}\".format(np.mean(scores)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mean cross-validation accuracy: 0.881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6oxfNIGAn7E",
        "colab_type": "code",
        "outputId": "32d6c0ef-21e9-41eb-caae-1b34907484fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Best parameters: \", grid.best_params_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.89\n",
            "Best parameters:  {'C': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuCoKl3NBSug",
        "colab_type": "text"
      },
      "source": [
        "Now, let’s see if we can improve the extraction of words. The CountVectorizer\n",
        "extracts tokens using a regular expression. By default, the regular expression that is\n",
        "used is \"\\b\\w\\w+\\b\". If you are not familiar with regular expressions, this means it\n",
        "finds all sequences of characters that consist of at least two letters or numbers (\\w)\n",
        "and that are separated by word boundaries (\\b). It does not find single-letter words,\n",
        "and it splits up contractions like “doesn’t” or “bit.ly”, but it matches “h8ter” as a single\n",
        "word. The CountVectorizer then converts all words to lowercase characters, so that\n",
        "“soon”, “Soon”, and “sOon” all correspond to the same token (and therefore feature).\n",
        "This simple mechanism works quite well in practice, but as we saw earlier, we get\n",
        "many uninformative features (like the numbers). One way to cut back on these is to\n",
        "only use tokens that appear in at least two documents (or at least five documents, and\n",
        "so on). A token that appears only in a single document is unlikely to appear in the test\n",
        "set and is therefore not helpful. We can set the minimum number of documents a\n",
        "token needs to appear in with the min_df parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qiBCoZtBROq",
        "colab_type": "code",
        "outputId": "7b510d3c-b592-44f6-bb25-afbf6a355e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "vect = CountVectorizer(min_df=5).fit(text_train)\n",
        "X_train = vect.transform(text_train)\n",
        "print(\"X_train with min_df: {}\".format(repr(X_train)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train with min_df: <25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3354014 stored elements in Compressed Sparse Row format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxHGDaNCBiOR",
        "colab_type": "code",
        "outputId": "8f060afd-bcb1-49e1-a9cd-3c1ff2189a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "feature_names = vect.get_feature_names()\n",
        "\n",
        "print(\"First 50 features:\\n{}\".format(feature_names[:50]))\n",
        "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
        "print(\"Every 700th feature:\\n{}\".format(feature_names[::700]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 50 features:\n",
            "['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '100', '1000', '100th', '101', '102', '103', '104', '105', '107', '108', '10s', '10th', '11', '110', '112', '116', '117', '11th', '12', '120', '12th', '13', '135', '13th', '14', '140', '14th', '15', '150', '15th', '16', '160', '1600', '16mm', '16s', '16th']\n",
            "Features 20010 to 20030:\n",
            "['repentance', 'repercussions', 'repertoire', 'repetition', 'repetitions', 'repetitious', 'repetitive', 'rephrase', 'replace', 'replaced', 'replacement', 'replaces', 'replacing', 'replay', 'replayable', 'replayed', 'replaying', 'replays', 'replete', 'replica']\n",
            "Every 700th feature:\n",
            "['00', 'affections', 'appropriately', 'barbra', 'blurbs', 'butchered', 'cheese', 'commitment', 'courts', 'deconstructed', 'disgraceful', 'dvds', 'eschews', 'fell', 'freezer', 'goriest', 'hauser', 'hungary', 'insinuate', 'juggle', 'leering', 'maelstrom', 'messiah', 'music', 'occasional', 'parking', 'pleasantville', 'pronunciation', 'recipient', 'reviews', 'sas', 'shea', 'sneers', 'steiger', 'swastika', 'thrusting', 'tvs', 'vampyre', 'westerns']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LjY1coDCADf",
        "colab_type": "code",
        "outputId": "8173b7cc-bb66-4a18-8fe8-3063f0539210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5).fit(X_train, y_train)\n",
        "print(\"Best cross-validation score: {}\".format(grid.best_score_))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.88812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyq2feKKCNcq",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ty2To2gpw9",
        "colab_type": "text"
      },
      "source": [
        "## Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6gHil9lhOGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "b9294aab-e677-4ff3-c984-0194b83abfa1"
      },
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
        "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of stop words: 318\n",
            "Every 10th stopword:\n",
            "['it', 'towards', 'already', 'describe', 'own', 'call', 'myself', 'ie', 'except', 'eleven', 'front', 'some', 'this', 'hereafter', 'wherein', 'amount', 'forty', 'sincere', 'over', 'system', 'whereafter', 'cannot', 'somehow', 'twelve', 'also', 'neither', 'therefore', 'although', 'but', 'sometimes', 'across', 'sometime']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqqMBFokh-Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect = CountVectorizer(min_df=5, stop_words='english').fit(text_train)\n",
        "X_train = vect.transform(text_train)\n",
        "print(\"X_train with stop words:\\n{}\".format(repr(X_train)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG8L5IF1i6MY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "6b5962cc-0d7e-45e6-d6d9-42b563c6e891"
      },
      "source": [
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best score-validation score: {}\".format(grid.best_score_))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score-validation score: 0.88812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ftppFdjOO7",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV8wKLygjdcG",
        "colab_type": "text"
      },
      "source": [
        "## Rescaling the Data with tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGRrUf9NjgsC",
        "colab_type": "text"
      },
      "source": [
        "Instead of dropping features that are deemed unimportant, another approach is to\n",
        "rescale features by how informative we expect them to be. One of the most common\n",
        "ways to do this is using the term frequency–inverse document frequency (tf–idf)\n",
        "method. The intuition of this method is to give high weight to any term that appears\n",
        "often in a particular document, but not in many documents in the corpus. If a word\n",
        "appears often in a particular document, but not in very many documents, it is likely\n",
        "to be very descriptive of the content of that document. scikit-learn implements the\n",
        "tf–idf method in two classes: TfidfTransformer, which takes in the sparse matrix\n",
        "output produced by CountVectorizer and transforms it, and TfidfVectorizer,\n",
        "which takes in the text data and does both the bag-of-words feature extraction and\n",
        "the tf–idf transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evPAXIdzkUDW",
        "colab_type": "text"
      },
      "source": [
        "tfidf$(w, d) = tf * log\\frac{N + 1}{N_w + 1} + 1$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG0tKB0tku8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8973487-978a-4893-e13d-5a9e0b3d297a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipe = make_pipeline(TfidfVectorizer(min_df=5), \n",
        "                     LogisticRegression())\n",
        "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
        "\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5).fit(text_train, y_train)\n",
        "print(\"Best cross-validation score: {}\".format(grid.best_score_))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 0.89188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Er4Bl0l9TW",
        "colab_type": "text"
      },
      "source": [
        "In this case, tf–idf had no impact. We can also inspect which words tf–idf found most\n",
        "important. Keep in mind that the tf–idf scaling is meant to find words that distinguish\n",
        "documents, but it is a purely unsupervised technique. So, “important” here does\n",
        "not necessarily relate to the “positive review” and “negative review” labels we are\n",
        "interested in. First, we extract the TfidfVectorizer from the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEQW1tQPmfcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "ef77c2bf-f15e-454a-bc20-81c6a0d3ca18"
      },
      "source": [
        "vectorizer = grid.best_estimator_.named_steps['tfidfvectorizer']\n",
        "# transform the trainigng dataset\n",
        "X_train = vectorizer.transform(text_train)\n",
        "# find the maximum value for each of the features over the dataset\n",
        "max_value = X_train.max(0).toarray().ravel()\n",
        "sorted_by_tfidf = max_value.argsort()\n",
        "# get feature names\n",
        "feature_names = np.array(vectorizer.get_feature_names())\n",
        "\n",
        "print(\"Features with lowest tfidf:\\n{}\".format(\n",
        "feature_names[sorted_by_tfidf[:20]]))\n",
        "print(\"Features with highest tfidf: \\n{}\".format(\n",
        "feature_names[sorted_by_tfidf[-20:]]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features with lowest tfidf:\n",
            "['suplexes' 'gauche' 'hypocrites' 'oncoming' 'songwriting' 'galadriel'\n",
            " 'emerald' 'mclaughlin' 'sylvain' 'oversee' 'cataclysmic' 'pressuring'\n",
            " 'uphold' 'thieving' 'inconsiderate' 'ware' 'denim' 'reverting' 'booed'\n",
            " 'spacious']\n",
            "Features with highest tfidf: \n",
            "['gadget' 'sucks' 'zatoichi' 'demons' 'lennon' 'bye' 'dev' 'weller'\n",
            " 'sasquatch' 'botched' 'xica' 'darkman' 'woo' 'casper' 'doodlebops'\n",
            " 'smallville' 'wei' 'scanners' 'steve' 'pokemon']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt-w2098nJP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "48b5c7b0-5d62-4f0f-ca12-f0e4f96eca41"
      },
      "source": [
        "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
        "print(\"Features with lowest idf:\\n{}\".format(\n",
        "feature_names[sorted_by_idf[:100]]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features with lowest idf:\n",
            "['the' 'and' 'of' 'to' 'this' 'is' 'it' 'in' 'that' 'but' 'for' 'with'\n",
            " 'was' 'as' 'on' 'movie' 'not' 'have' 'one' 'be' 'film' 'are' 'you' 'all'\n",
            " 'at' 'an' 'by' 'so' 'from' 'like' 'who' 'they' 'there' 'if' 'his' 'out'\n",
            " 'just' 'about' 'he' 'or' 'has' 'what' 'some' 'good' 'can' 'more' 'when'\n",
            " 'time' 'up' 'very' 'even' 'only' 'no' 'would' 'my' 'see' 'really' 'story'\n",
            " 'which' 'well' 'had' 'me' 'than' 'much' 'their' 'get' 'were' 'other'\n",
            " 'been' 'do' 'most' 'don' 'her' 'also' 'into' 'first' 'made' 'how' 'great'\n",
            " 'because' 'will' 'people' 'make' 'way' 'could' 'we' 'bad' 'after' 'any'\n",
            " 'too' 'then' 'them' 'she' 'watch' 'think' 'acting' 'movies' 'seen' 'its'\n",
            " 'him']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxqxqHAWnn2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}