{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mglearn\n",
    "\n",
    "# dataset\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We might be tempted to add more features to get better performance, but adding more features makes all models more complex, and increase the chance of overfitting.\n",
    "- With high-dimesionality datasets it can be a good idea to reduce the number of features to only the most useful ones, and discard the rest.\n",
    "- There are three basic strategies of feature selection: univariate statistics, model based selection, and iterative selection.\n",
    "- All of these methods are supervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We compute whether there is statistically significant relationship between feature to target vector, then features that are related with the highest confidence are selected.\n",
    "- They are univariate which means they consider it individually, consequently it will be discarded if it is informative when combined with others.\n",
    "- Fast to compute and don't require building a model. On the other hand, they are completely independent of the model that you might want to apply after the feature selection.\n",
    "- To use univariate feature selection, we have to choose f_classif (for classification) and f_regression (for regression).\n",
    "- Method to discard features based on p-values determined in the test.\n",
    "- All methods for discarding parameters use a threshold to discard all features with too high a p-value (which means they are unlikely to be related to the target).\n",
    "- The methods differ in how they compute this threshold, with the simplest ones being SelectKB est, which selects a fixed number k of features, and SelectPercentile, which selects a fixed percentage of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it harder we add noise to the dataset, breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (284, 80)\n",
      "X_train_selected.shape: (284, 40)\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "# get deterministic random numbers\n",
    "# get deterministic random numbers\n",
    "rng = np.random.RandomState(42)\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "# add noise features to the data\n",
    "# the first 30 features are from the dataset, the next 50 are noise\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, \n",
    "                                                    random_state=0, test_size=.5)\n",
    "# use f_classif (the default) and SelectPercentile to select 50% of features.\n",
    "select = SelectPercentile(percentile=50).fit(X_train, y_train)\n",
    "# transforming the trainig set\n",
    "X_train_selected = select.transform(X_train)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80)\n"
     ]
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "print(mask.reshape(1, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAAA4CAYAAACPHscHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACdVJREFUeJzt3WuMHWUdx/HvjyIqoOFWDbFAJSKCRgoFhGAQgRBQAiZilEACxoQYeaFRYrwQESMveIMaryBeSFRQEYVgYkqQihpFWEALVAFJEQLSNop4SYqUvy/OU7uuq93ZPafnzPL9JM2ZeWZ25un5nZmz/84z01QVkiRJkiTN1Q7j7oAkSZIkqV8sJCVJkiRJnVhISpIkSZI6sZCUJEmSJHViISlJkiRJ6sRCUpIkSZLUyYIKySQnJ/ldkgeTfGhYndJoJPlqkvVJ7pnWtkeSm5I80F53H2cfNbsk+yS5JcnaJPcmeW9rN78eSPKCJL9K8uuW38Wt/eVJbmv5fTvJTuPuq2aXZEmSu5Lc2ObNrieSrEuyJsndSe5obZ47eyDJbkmuTfLb9v13tNn1Q5ID2zG35c9TSd5nfovLvAvJJEuAzwOnAAcDZyY5eFgd00h8HTh5RtuHgJur6gDg5javyfMM8IGqOgg4Cji/HW/m1w+bgOOr6hBgBXBykqOAS4FPtfz+DLxrjH3U//deYO20ebPrlzdW1YqqOrzNe+7sh88AP6qqVwGHMDgGza4Hqup37ZhbAawE/gF8H/NbVBZyRfJI4MGqeqiqngauAU4fTrc0ClV1K/CnGc2nA1e16auAt2zXTmlOqurxqrqzTf+VwZfpyzC/XqiBv7XZ57U/BRwPXNvazW9CJVkGvBm4ss0Hs+s7z50TLsmLgWOBrwBU1dNV9SRm10cnAL+vqocxv0VlIYXky4BHps0/2trULy+tqsdhUKwALxlzf7QNSZYDhwK3YX690YZG3g2sB24Cfg88WVXPtFU8h06uTwMfBJ5t83tidn1SwKokU0nOa22eOyff/sAG4GttWPmVSXbB7ProHcDVbdr8FpGFFJKZpa0WsD1J25BkV+B7wPuq6qlx90dzV1Wb2xCfZQxGdBw022rbt1faliSnAuuramp68yyrmt3kOqaqDmNwK875SY4dd4c0JzsChwFfrKpDgb/jMMjeafePnwZ8d9x90fAtpJB8FNhn2vwy4LGFdUdj8ESSvQHa6/ox90f/Q5LnMSgiv1lV17Vm8+uZNjRrNYN7XXdLsmNb5Dl0Mh0DnJZkHYNbOI5ncIXS7Hqiqh5rr+sZ3KN1JJ47++BR4NGquq3NX8ugsDS7fjkFuLOqnmjz5reILKSQvB04oD25bicGl61vGE63tB3dAJzTps8Brh9jX/Q/tHuyvgKsrarLpi0yvx5IsjTJbm36hcCJDO5zvQU4o61mfhOoqj5cVcuqajmD77kfV9VZmF0vJNklyYu2TAMnAffguXPiVdUfgUeSHNiaTgDuw+z65ky2DmsF81tUUjX/0ThJ3sTgX2aXAF+tqkuG1TENX5KrgeOAvYAngIuAHwDfAfYF/gC8rapmPpBHY5bk9cBPgTVsvU/rIwzukzS/CZfktQweKrCEwT/gfaeqPpFkfwZXufYA7gLOrqpN4+up/p8kxwEXVNWpZtcPLafvt9kdgW9V1SVJ9sRz58RLsoLBQ652Ah4C3kk7h2J2Ey/Jzgyep7J/Vf2ltXnsLSILKiQlSZIkSc89CxnaKkmSJEl6DrKQlCRJkiR1YiEpSZIkSerEQlKSJEmS1ImFpCRJkiSpkwUXkknOG0ZHNB7m119m12/m12/m119m12/m119mt/gM44qkH4p+M7/+Mrt+M79+M7/+Mrt+M7/+MrtFxqGtkiRJkqROUlVzXzmZ+8oauZUrV3Zaf2pqaiTb7rLdxa5rJnPle9xvs30uNmzYwNKlS7dbH7p+hkZ1DpiEY2QYfZjk/CbhPZ6UfnQ59ibhPe6jxX5uGaVJ+L1se75vwzpvjup3osXwHg/L1NTUxqraZlgWkj3WJTuAJCPZdpftLnZdM5kr3+N+G9Xnoouun6FRnQMm4RiZhDy6moS/3yg/Q6PqR98+x3202M8to+RneX5G9TuR7/FWSaaq6vBtrefQVkmSJElSJxaSkiRJkqROLCQlSZIkSZ1YSEqSJEmSOrGQlCRJkiR1YiEpSZIkSerEQlKSJEmS1ImFpCRJkiSpEwtJSZIkSVInqaq5r5xsAB6e0bwXsHGYndJ2ZX79ZXb9Zn79Zn79ZXb9Zn79ZXb9sV9VLd3WSp0KyVk3kNxRVYcvaCMaG/PrL7PrN/PrN/PrL7PrN/PrL7NbfBzaKkmSJEnqxEJSkiRJktTJMArJK4awDY2P+fWX2fWb+W1Dko8muTfJb5LcneR1I97f6iRzHXZ1RZJPJDmx4z7WJdlrHt3T8Hjs9Zv59ZfZLTILvkdSkqRhS3I0cBlwXFVtasXXTlX12Aj3uRq4oKruGOE+1gGHV5UPnJAk9ZpDWyVJk2hvYGNVbQKoqo1bisgkH0tye5J7klyRJK19dZJPJbk1ydokRyS5LskDST7Z1lme5LdJrmpXOq9NsvPMnSc5KckvktyZ5LtJdp1lna8nOaNNr0tycVt/TZJXtfY9k6xKcleSy4FM+/mzk/yqXW29PMmSJPu1/u6VZIckP01y0vDfXkmSFsZCUpI0iVYB+yS5P8kXkrxh2rLPVdURVfUa4IXAqdOWPV1VxwJfAq4HzgdeA5ybZM+2zoHAFVX1WuAp4D3Td9yufl4InFhVhwF3AO+fQ583tvW/CFzQ2i4CflZVhwI3APu2fRwEvB04pqpWAJuBs6rqYeDS1v8PAPdV1ao57FuSpO3KQlKSNHGq6m/ASuA8YAPw7STntsVvTHJbkjXA8cCrp/3oDe11DXBvVT3ermo+BOzTlj1SVT9v098AXj9j90cBBwM/T3I3cA6w3xy6fV17nQKWt+lj2z6oqh8Cf27tJ7S/3+1tHycA+7f1rgReBLybrQWpJEkTZcdxd0CSpNlU1WZgNbC6FY3nJLkG+AKD+wwfSfJx4AXTfmxTe3122vSW+S3feTMfDjBzPsBNVXVmxy5v2d9m/vP7dbaHEQS4qqo+/F8LBkNtl7XZXYG/duyHJEkj5xVJSdLESXJgkgOmNa0AHmZr0bix3bd4xjw2v297mA/AmcDPZiz/JXBMkle0vuyc5JXz2A/ArcBZbTunALu39puBM5K8pC3bI8mWq56XAt8EPgZ8eZ77lSRppLwiKUmaRLsCn02yG/AM8CBwXlU9meTLDIaurgNun8e21zK4unk58ACDexr/rao2tGG0Vyd5fmu+ELh/Hvu6uG3nTuAnwB/aPu5LciGwKskOwD+B85MsB45gcO/k5iRvTfLOqvraPPYtSdLI+N9/SJKeM1qhdmN7UI8kSZonh7ZKkiRJkjrxiqQkSZIkqROvSEqSJEmSOrGQlCRJkiR1YiEpSZIkSerEQlKSJEmS1ImFpCRJkiSpEwtJSZIkSVIn/wKb9oSkrO6qzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the mask -- black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agus Richard Lubis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with all features: 0.930\n",
      "Score with only selected features: 0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agus Richard Lubis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# transform test data\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Score with all features: {:.3f}\".format(lr.score(X_test, y_test)))\n",
    "lr = LogisticRegression().fit(X_train_selected, y_train)\n",
    "print(\"Score with only selected features: {:.3f}\".format(lr.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the dataset is highly dimensional and that building a model is infeasible, we can use feature selection to discard uninformative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Based Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model based feature selection uses a supervised machine learning model to judge the importance of each feature, and keeps the important ones.\n",
    "- The supervised model used for feature selection does not have to be the same as supervised model used for final modeling.\n",
    "- Decision trees and decision tree–based models provide a feature_importances_, attribute, which directly encodes the importance of each feature.\n",
    "- Linear models have coefficients, which can also be used to capture feature importances by considering the absolute values.\n",
    "- In contrast to univariate selection, model-based selection considers all features at once, and so can capture interactions (if the model can capture them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "                        threshold='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The SelectFromModel class selects all features that have an importance measure of the feature (as provided by the supervised model) greater than the provided threshold.\n",
    "- We use threshold='median', because we want to compare it with univariate statistics feature selection (select half)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (284, 80)\n",
      "X_train_l1.shape: (284, 40)\n"
     ]
    }
   ],
   "source": [
    "select.fit(X_train, y_train)\n",
    "X_train_l1 = select.transform(X_train)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_l1.shape: {}\".format(X_train_l1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "# visualize the mask -- black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agus Richard Lubis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_test_l1 = select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_l1, y_train).score(X_test_l1, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In univariate feature selection we use no model, in model-based feature selection we use one model.\n",
    "- In iterative feature selection, a series of models are built, with varying number of features.\n",
    "- There are two basic methods: starting with no features and adding features one by one until some stopping criterion is reached, or starting with all features and removing features one by one until some stopping criterionis reached.\n",
    "- Downside: Computationaly expensive.\n",
    "- One particular method of this kind is recursive feature elimination (RFE), which starts with all features, builds a model, and discards the least important feature according to the model. Then a new model is built using all but the discarded feature, and so on until only a prespecified number of features are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "n_features_to_select=40).fit(X_train, y_train)\n",
    "\n",
    "# visualize the selected features:\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.yticks(());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes longer because we train random forest 40 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9508771929824561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agus Richard Lubis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_rfe = select.transform(X_train)\n",
    "X_test_rfe = select.transform(X_test)\n",
    "\n",
    "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test)\n",
    "print(\"Test score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the model used inside the RFE to make predictions. This uses only\n",
    "the feature set that was selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.951\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score: {:.3f}\".format(select.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most real-world cases, applying feature selection is\n",
    "unlikely to provide large gains in performance. However, it is still a valuable tool in\n",
    "the toolbox of the feature engineer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can reduce dimensionality by using feature selection.\n",
    "- These three methods are supervised methods.\n",
    "- Univariate Statistics:\n",
    "    - Compute whether there is statistically significant relationship between features and target.\n",
    "    - Using p-values to determine it.\n",
    "    - Feature inspection works individually, so feature that works only when combined will be discarded.\n",
    "    - Fast, no need to built a model.\n",
    "    - Choice: f_classif for classification and f_regression for regression.\n",
    "    - Methods of univariate feature selection:\n",
    "        - SelectKBest: selecting K important features.\n",
    "        - SelectPercentile: selecting percentage of all features.\n",
    "    - SelectPercentile: \n",
    "        - Parameter: percentile (0-100)\n",
    "        - Methods:\n",
    "            - fit(), ex: select.fit(X_train, y_train)\n",
    "            - transform(), ex: select.transform(X_train)\n",
    "            - get_support(): returning masking of features\n",
    "- Model-Based feature selection:\n",
    "    - Need model.\n",
    "    - Use the provided feature importances of each feature.\n",
    "    - SelectFromModel:\n",
    "        - Parameters: \n",
    "            - Model\n",
    "            - Threshold\n",
    "        - Methods:\n",
    "            - fit()\n",
    "            - transform()\n",
    "            - get_support(): returning masking of features\n",
    "- Iterative Feature Selection:\n",
    "    - Use a series of model with different number of parameters.\n",
    "    - Iteratively adding important features or deleting unsignificant features.\n",
    "    - Downside: Computationaly expensive.\n",
    "    - Recursive Feature Elimination  (RFE):\n",
    "        - Parameters:\n",
    "            - Model\n",
    "            - n_features_to_select\n",
    "        - Methods:\n",
    "            - fit()\n",
    "            - transform()\n",
    "            - get_support(): returning masking of features\n",
    "- We can visualize feature selection we plt.matshow()\n",
    "- We can use methods and attributes from model inside SelectFromModel or RFE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
